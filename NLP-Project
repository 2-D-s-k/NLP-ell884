{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5382110,"sourceType":"datasetVersion","datasetId":3121327}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers --quiet\n!pip install datasets --quiet\n!pip install sentencepiece --quiet\n!pip install accelerate --quiet\n!pip install -U nltk","metadata":{"id":"9IL6D7WYTR--","outputId":"7ee73fe7-70c7-4eb9-e8c3-c5de37b2a466","execution":{"iopub.status.busy":"2025-04-06T03:53:05.996020Z","iopub.execute_input":"2025-04-06T03:53:05.996392Z","iopub.status.idle":"2025-04-06T03:53:24.561282Z","shell.execute_reply.started":"2025-04-06T03:53:05.996348Z","shell.execute_reply":"2025-04-06T03:53:24.560351Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\nDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.9.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install sacrebleu --quiet\n!pip install bert_score --quiet\n!pip install git+https://github.com/google-research/bleurt.git --quiet","metadata":{"id":"vK5CJcwswLbF","outputId":"624e8cb0-7392-47c6-ced6-6bfc9ecce486","execution":{"iopub.status.busy":"2025-04-06T03:53:24.562654Z","iopub.execute_input":"2025-04-06T03:53:24.562979Z","iopub.status.idle":"2025-04-06T03:53:40.095174Z","shell.execute_reply.started":"2025-04-06T03:53:24.562944Z","shell.execute_reply":"2025-04-06T03:53:40.094155Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:53:40.097314Z","iopub.execute_input":"2025-04-06T03:53:40.097668Z","iopub.status.idle":"2025-04-06T03:53:43.691311Z","shell.execute_reply.started":"2025-04-06T03:53:40.097633Z","shell.execute_reply":"2025-04-06T03:53:43.690262Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport os\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nfrom torch.utils.data import DataLoader\nimport nltk\nnltk.download(\"punkt\", quiet=True)\n\n# from datasets import load_dataset, load_metric\nfrom datasets import load_dataset\nimport evaluate\n\nimport transformers\nfrom transformers import (\n    AutoConfig,\n    AutoModelForSeq2SeqLM,\n    AutoTokenizer,\n    DataCollatorForSeq2Seq,\n    HfArgumentParser,\n    MBartTokenizer,\n    MBartTokenizerFast,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    default_data_collator,\n    set_seed,\n)\nfrom transformers.trainer_utils import (\n    get_last_checkpoint, \n    is_main_process, \n    default_compute_objective,\n    # default_hp_space_ray\n)\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['WANDB_DISABLED'] = 'true'","metadata":{"id":"8ZLkXIActFdK","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:53:43.693057Z","iopub.execute_input":"2025-04-06T03:53:43.693358Z","iopub.status.idle":"2025-04-06T03:54:06.064038Z","shell.execute_reply.started":"2025-04-06T03:53:43.693333Z","shell.execute_reply":"2025-04-06T03:54:06.063387Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def seed_everything(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    set_seed(seed)\n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\nseed_everything(42)   ","metadata":{"id":"Qklt1jNwtCfb","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:54:06.064844Z","iopub.execute_input":"2025-04-06T03:54:06.065341Z","iopub.status.idle":"2025-04-06T03:54:06.131075Z","shell.execute_reply.started":"2025-04-06T03:54:06.065318Z","shell.execute_reply":"2025-04-06T03:54:06.130419Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"DongfuJiang/FeTaQA\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:54:06.131799Z","iopub.execute_input":"2025-04-06T03:54:06.132012Z","iopub.status.idle":"2025-04-06T03:54:09.617761Z","shell.execute_reply.started":"2025-04-06T03:54:06.131993Z","shell.execute_reply":"2025-04-06T03:54:09.617117Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/663 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0639b14a177d49198129c4db56391b63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"fetaQA-v1_train.jsonl:   0%|          | 0.00/14.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7ead29b82d458fbf08f982198c976b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"fetaQA-v1_dev.jsonl:   0%|          | 0.00/1.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe4dbba1ea94417b54fd596b5791496"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"fetaQA-v1_test.jsonl:   0%|          | 0.00/3.61M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ef9892f9ab14ef2bf20d4e8b7bc86bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7326 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7090e7cd933048a0bd36f476dc0a3db3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"187682fb847a49f9b3abd9a12f3a9ceb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a000c4d72af5446ba973dcf44e6897dc"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('json', data_files={'train': '/kaggle/input/tableqa/fetaQA-v1_train.json', 'valid': '/kaggle/input/tableqa/fetaQA-v1_dev.json', 'test': '/kaggle/input/tableqa/fetaQA-v1_test.json'}, field='data')","metadata":{"id":"BI75mzhOvdbW","outputId":"fc0d9d7c-5518-47fa-e628-ee5e03c9a687","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:54:09.618578Z","iopub.execute_input":"2025-04-06T03:54:09.618820Z","iopub.status.idle":"2025-04-06T03:54:09.973290Z","shell.execute_reply.started":"2025-04-06T03:54:09.618786Z","shell.execute_reply":"2025-04-06T03:54:09.970931Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-9f15e123b03e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'/kaggle/input/tableqa/fetaQA-v1_train.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'/kaggle/input/tableqa/fetaQA-v1_dev.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'/kaggle/input/tableqa/fetaQA-v1_test.json'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   2130\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1849\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1850\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1562\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         ).get_module()\n\u001b[0m\u001b[1;32m   1565\u001b[0m     \u001b[0;31m# Try locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mget_data_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         )\n\u001b[0;32m--> 944\u001b[0;31m         data_files = DataFilesDict.from_patterns(\n\u001b[0m\u001b[1;32m    945\u001b[0m             \u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFilesList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 else DataFilesList.from_patterns(\n\u001b[0m\u001b[1;32m    722\u001b[0m                     \u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 data_files.extend(\n\u001b[0;32m--> 624\u001b[0;31m                     resolve_pattern(\n\u001b[0m\u001b[1;32m    625\u001b[0m                         \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                         \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mallowed_extensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\" with any supported extension {list(allowed_extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find '/kaggle/input/tableqa/fetaQA-v1_train.json'"],"ename":"FileNotFoundError","evalue":"Unable to find '/kaggle/input/tableqa/fetaQA-v1_train.json'","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"dataset","metadata":{"id":"hKpyTNZSZ1Sl","outputId":"ed8a251c-d563-4111-c350-671bd19a9f60","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:54:29.017902Z","iopub.execute_input":"2025-04-06T03:54:29.018214Z","iopub.status.idle":"2025-04-06T03:54:29.023547Z","shell.execute_reply.started":"2025-04-06T03:54:29.018188Z","shell.execute_reply":"2025-04-06T03:54:29.022617Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['feta_id', 'table_source_json', 'page_wikipedia_url', 'table_page_title', 'table_section_title', 'table_array', 'highlighted_cell_ids', 'question', 'answer'],\n        num_rows: 7326\n    })\n    validation: Dataset({\n        features: ['feta_id', 'table_source_json', 'page_wikipedia_url', 'table_page_title', 'table_section_title', 'table_array', 'highlighted_cell_ids', 'question', 'answer'],\n        num_rows: 1001\n    })\n    test: Dataset({\n        features: ['feta_id', 'table_source_json', 'page_wikipedia_url', 'table_page_title', 'table_section_title', 'table_array', 'highlighted_cell_ids', 'question', 'answer'],\n        num_rows: 2003\n    })\n})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dataset['train'][0]['answer']","metadata":{"id":"Uz8aIhW3wTQk","outputId":"82d41b5a-53b9-4619-b0d6-c3bf2b3c3bf3","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:54:34.306971Z","iopub.execute_input":"2025-04-06T03:54:34.307277Z","iopub.status.idle":"2025-04-06T03:54:34.314484Z","shell.execute_reply.started":"2025-04-06T03:54:34.307250Z","shell.execute_reply":"2025-04-06T03:54:34.313703Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'Thompson prevailed in the 1982 Illinois gubernatorial election by a 5,074 vote margin.'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(\"t5-base\")\ntokenizer = AutoTokenizer.from_pretrained(\"t5-base\")","metadata":{"id":"u1zhCZJZaE3n","outputId":"11d5b739-eeda-4745-8e18-d5e423e396a7","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:54:37.402788Z","iopub.execute_input":"2025-04-06T03:54:37.403062Z","iopub.status.idle":"2025-04-06T03:54:39.288009Z","shell.execute_reply.started":"2025-04-06T03:54:37.403040Z","shell.execute_reply":"2025-04-06T03:54:39.287354Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d264d9c26a43179ba24f220c808da3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bce15000d4943d7a2e3a77240e68f00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09cbf8b0289247bdbe4f7ffe42177696"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def linearize_table_context(table_array, question):\n    return '[CLS]' + question + '[CLS]' + ('[SEP]'.join([' '.join(row) for row in table_array]))","metadata":{"id":"1eike-4wu0NV","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:54:46.696126Z","iopub.execute_input":"2025-04-06T03:54:46.696448Z","iopub.status.idle":"2025-04-06T03:54:46.700310Z","shell.execute_reply.started":"2025-04-06T03:54:46.696417Z","shell.execute_reply":"2025-04-06T03:54:46.699422Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def preprocess_examples(examples):\n    prefix = 'summarize: '\n    answers = examples['answer']\n    \n    inputs = [\n        prefix + linearize_table_context(table, question) for table, question in zip(examples['table_array'], examples['question'])\n    ]\n\n    model_inputs = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True)\n    labels = tokenizer(answers, max_length=64, padding=\"max_length\", truncation=True).input_ids\n\n    # We need to replace the index of the padding tokens by -100\n    # such that they are not taken into account by the CrossEntropyLoss\n\n    labels_with_ignore_index = []\n    for labels_example in labels:\n      labels_example = [label if label != 0 else -100 for label in labels_example]\n      labels_with_ignore_index.append(labels_example)\n    \n    model_inputs[\"labels\"] = labels_with_ignore_index\n\n    return model_inputs","metadata":{"id":"6AeZQpPWtybL","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:54:50.111045Z","iopub.execute_input":"2025-04-06T03:54:50.111363Z","iopub.status.idle":"2025-04-06T03:54:50.116828Z","shell.execute_reply.started":"2025-04-06T03:54:50.111332Z","shell.execute_reply":"2025-04-06T03:54:50.115876Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"encoded_train_ds = dataset['train'].map(preprocess_examples, batched=True, remove_columns=dataset['train'].column_names)\nencoded_val_ds = dataset['validation'].map(preprocess_examples, batched=True, remove_columns=dataset['validation'].column_names)\nencoded_test_ds = dataset['test'].map(preprocess_examples, batched=True, remove_columns=dataset['test'].column_names)","metadata":{"id":"TmFV4wTovSgA","outputId":"09a4eacb-4c17-424c-fce1-e97e063d8c9c","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:54:54.493392Z","iopub.execute_input":"2025-04-06T03:54:54.493730Z","iopub.status.idle":"2025-04-06T03:55:08.497245Z","shell.execute_reply.started":"2025-04-06T03:54:54.493702Z","shell.execute_reply":"2025-04-06T03:55:08.496341Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7326 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"426f1063225142cdad63bd3a86d126e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e94e9990ffb48319bb3126cc0f17eed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bb73f6e01524cdf90965d772abe7925"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def postprocess_text(preds, labels, metric_name):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n\n    # rougeLSum expects newline after each sentence\n    if metric_name == \"rouge\":\n        preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n        labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n\n    # sacrebleu expects list of references for each prediction\n    elif metric_name == \"sacrebleu\":\n        labels = [[label] for label in labels]\n\n    # For BLEU metric in `evaluate`, keep plain strings\n    elif metric_name == \"bleu\":\n        # Don't tokenize manually — let evaluate handle it\n        pass\n\n    return preds, labels\n","metadata":{"id":"ZwxOJ4A61DYq","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:15:45.890962Z","iopub.execute_input":"2025-04-06T10:15:45.891293Z","iopub.status.idle":"2025-04-06T10:15:45.896773Z","shell.execute_reply.started":"2025-04-06T10:15:45.891266Z","shell.execute_reply":"2025-04-06T10:15:45.895841Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(\n    \"t5-base\",\n    from_tf=False,\n    config=config,\n)\nmodel.resize_token_embeddings(len(tokenizer))\n\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer,\n    label_pad_token_id=-100,\n)","metadata":{"id":"mAx7Gb6EzS33","outputId":"e832810b-1f2d-495b-bfb9-0bdcc57a8645","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:15:51.462870Z","iopub.execute_input":"2025-04-06T10:15:51.463171Z","iopub.status.idle":"2025-04-06T10:15:52.291770Z","shell.execute_reply.started":"2025-04-06T10:15:51.463145Z","shell.execute_reply":"2025-04-06T10:15:52.290830Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"import json\ndef save_json(content, path, indent=4, **json_dump_kwargs):\n    with open(path, \"w\") as f:\n        json.dump(content, f, indent=indent, sort_keys=True, **json_dump_kwargs)","metadata":{"id":"5cFB56886YwO","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:15:56.145922Z","iopub.execute_input":"2025-04-06T10:15:56.146201Z","iopub.status.idle":"2025-04-06T10:15:56.150433Z","shell.execute_reply.started":"2025-04-06T10:15:56.146179Z","shell.execute_reply":"2025-04-06T10:15:56.149411Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"/kaggle/working/\",\n    overwrite_output_dir=False,\n    do_train=True,\n    do_eval=True,\n    do_predict=True,\n    num_train_epochs=30,              \n    per_device_train_batch_size=4,  \n    per_device_eval_batch_size=4,   \n    warmup_steps=500,                \n    weight_decay=0.01,               \n    predict_with_generate=True,\n    learning_rate=3e-05,\n    optim='adamw_torch', \n    save_strategy='steps',\n    save_steps=9160\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:16:00.350628Z","iopub.execute_input":"2025-04-06T10:16:00.350939Z","iopub.status.idle":"2025-04-06T10:16:00.385987Z","shell.execute_reply.started":"2025-04-06T10:16:00.350912Z","shell.execute_reply":"2025-04-06T10:16:00.385313Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"last_checkpoint = get_last_checkpoint(training_args.output_dir)","metadata":{"id":"uvAH4YRyeYxG","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:16:04.637248Z","iopub.execute_input":"2025-04-06T10:16:04.637602Z","iopub.status.idle":"2025-04-06T10:16:04.641723Z","shell.execute_reply.started":"2025-04-06T10:16:04.637568Z","shell.execute_reply":"2025-04-06T10:16:04.640868Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"print(last_checkpoint)","metadata":{"id":"NbJkVdD3z_kF","outputId":"0809c51f-83e0-425d-b679-b7c26fa97cf8","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:16:07.758277Z","iopub.execute_input":"2025-04-06T10:16:07.758588Z","iopub.status.idle":"2025-04-06T10:16:07.762657Z","shell.execute_reply.started":"2025-04-06T10:16:07.758564Z","shell.execute_reply":"2025-04-06T10:16:07.761806Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/checkpoint-54960\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import os\nimport numpy as np\n# from datasets import load_metric\nfrom evaluate import load as load_metric\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n\n    # Clip predictions to ensure valid token ids\n    preds = np.clip(preds, 0, tokenizer.vocab_size - 1).astype(int)\n    decoded_raw_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    # Replace -100 with pad_token_id, then clip and decode safely\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    labels = np.clip(labels, 0, tokenizer.vocab_size - 1).astype(int)\n    try:\n        decoded_raw_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    except Exception as e:\n        print(\"Decode error in labels:\", e)\n        decoded_raw_labels = [\"\"] * len(labels)\n\n    dic_pred_label = {'predictions': decoded_raw_preds, 'labels': decoded_raw_labels}\n    save_json(dic_pred_label, os.path.join(training_args.output_dir, \"detokenized_outputs.json\"))\n\n    result = {}\n    for metric_name in [\"meteor\", \"bleu\", \"sacrebleu\", \"bertscore\", \"bleurt\"]:\n        metric = load_metric(metric_name)\n        decoded_preds, decoded_labels = postprocess_text(decoded_raw_preds, decoded_raw_labels, metric_name)\n        \n        if metric_name == \"bertscore\":\n            res = metric.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n            for k, v in res.items():\n                if k == \"hashcode\":\n                    continue\n                result[f\"{metric_name}_{k}_0\"] = round(v[0], 2)\n                result[f\"{metric_name}_{k}_1\"] = round(v[1], 2)\n        else:\n            res = metric.compute(predictions=decoded_preds, references=decoded_labels)\n            if metric_name == \"sacrebleu\":\n                result[metric_name] = res[\"score\"]\n            elif metric_name == \"bleurt\":\n                result[f\"{metric_name}_0\"] = round(res[\"scores\"][0], 2)\n                result[f\"{metric_name}_1\"] = round(res[\"scores\"][1], 2)\n            else:\n                result[metric_name] = res[metric_name]\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:16:15.197582Z","iopub.execute_input":"2025-04-06T10:16:15.197904Z","iopub.status.idle":"2025-04-06T10:16:15.206779Z","shell.execute_reply.started":"2025-04-06T10:16:15.197878Z","shell.execute_reply":"2025-04-06T10:16:15.205919Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_train_ds,\n    eval_dataset=encoded_val_ds,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:16:19.724762Z","iopub.execute_input":"2025-04-06T10:16:19.725083Z","iopub.status.idle":"2025-04-06T10:16:20.405500Z","shell.execute_reply.started":"2025-04-06T10:16:19.725055Z","shell.execute_reply":"2025-04-06T10:16:20.404607Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-45-d8fc44bbcbec>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"all_metrics = {}\n\nif training_args.do_train:\n  if last_checkpoint is not None:\n    checkpoint = last_checkpoint\n  elif os.path.isdir(\"t5-base\"):\n    checkpoint = \"t5-base\"\n  else:\n    checkpoint = None\n\n  train_result = trainer.train(resume_from_checkpoint=checkpoint)\n  trainer.save_model()  # Saves the tokenizer too for easy upload\n\n  metrics = train_result.metrics\n  max_train_samples = (len(encoded_train_ds))\n  metrics[\"train_samples\"] = min(max_train_samples, len(encoded_train_ds))\n  if trainer.is_world_process_zero():\n    metrics_formatted = trainer.metrics_format(metrics)\n    print(\"***** train metrics *****\")\n    k_width = max(len(str(x)) for x in metrics_formatted.keys())\n    v_width = max(len(str(x)) for x in metrics_formatted.values())\n    for key in sorted(metrics_formatted.keys()):\n      print(f\"  {key: <{k_width}} = {metrics_formatted[key]:>{v_width}}\")\n    save_json(metrics, os.path.join(training_args.output_dir, \"train_results.json\"))\n    all_metrics.update(metrics)\n\n    # Need to save the state, since Trainer.save_model saves only the tokenizer with the model\n    trainer.state.save_to_json(os.path.join(training_args.output_dir, \"trainer_state.json\"))","metadata":{"id":"kfN2icgi5Lcg","outputId":"43fb4ea4-e7f0-43bd-ba68-4c6809fa71b6","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:56:00.034821Z","iopub.execute_input":"2025-04-06T03:56:00.035142Z","iopub.status.idle":"2025-04-06T09:16:05.568707Z","shell.execute_reply.started":"2025-04-06T03:56:00.035111Z","shell.execute_reply":"2025-04-06T09:16:05.567646Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='54960' max='54960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [54960/54960 5:20:01, Epoch 30/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.931500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.630000</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.538400</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.445400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.401500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.385600</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.388500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.301300</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.267700</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.277300</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.257300</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.206500</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.171300</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.173800</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.132700</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.117500</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.085900</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.089500</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>1.061900</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>1.033000</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>1.046400</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>1.044000</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.970900</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.984100</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.985300</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.957500</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.926800</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.925900</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.956200</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.905600</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>0.865800</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.903900</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>0.909900</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.829900</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>0.848800</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.857100</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>0.839300</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.808100</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>0.804900</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>0.812400</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>0.787600</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>0.779100</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>0.781700</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>0.786600</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>0.737800</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>0.737000</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>0.758900</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>0.752800</td>\n    </tr>\n    <tr>\n      <td>24500</td>\n      <td>0.723400</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>0.731000</td>\n    </tr>\n    <tr>\n      <td>25500</td>\n      <td>0.711200</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>0.699700</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>0.698800</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>0.698800</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>0.690800</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>0.655100</td>\n    </tr>\n    <tr>\n      <td>28500</td>\n      <td>0.672200</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>0.683600</td>\n    </tr>\n    <tr>\n      <td>29500</td>\n      <td>0.667200</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>0.659900</td>\n    </tr>\n    <tr>\n      <td>30500</td>\n      <td>0.651200</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>0.643500</td>\n    </tr>\n    <tr>\n      <td>31500</td>\n      <td>0.643200</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>0.623600</td>\n    </tr>\n    <tr>\n      <td>32500</td>\n      <td>0.626300</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>0.635500</td>\n    </tr>\n    <tr>\n      <td>33500</td>\n      <td>0.614000</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>0.624500</td>\n    </tr>\n    <tr>\n      <td>34500</td>\n      <td>0.622800</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>0.598900</td>\n    </tr>\n    <tr>\n      <td>35500</td>\n      <td>0.598400</td>\n    </tr>\n    <tr>\n      <td>36000</td>\n      <td>0.590400</td>\n    </tr>\n    <tr>\n      <td>36500</td>\n      <td>0.602800</td>\n    </tr>\n    <tr>\n      <td>37000</td>\n      <td>0.574300</td>\n    </tr>\n    <tr>\n      <td>37500</td>\n      <td>0.594800</td>\n    </tr>\n    <tr>\n      <td>38000</td>\n      <td>0.567900</td>\n    </tr>\n    <tr>\n      <td>38500</td>\n      <td>0.591800</td>\n    </tr>\n    <tr>\n      <td>39000</td>\n      <td>0.560500</td>\n    </tr>\n    <tr>\n      <td>39500</td>\n      <td>0.569900</td>\n    </tr>\n    <tr>\n      <td>40000</td>\n      <td>0.579000</td>\n    </tr>\n    <tr>\n      <td>40500</td>\n      <td>0.578900</td>\n    </tr>\n    <tr>\n      <td>41000</td>\n      <td>0.544800</td>\n    </tr>\n    <tr>\n      <td>41500</td>\n      <td>0.553500</td>\n    </tr>\n    <tr>\n      <td>42000</td>\n      <td>0.553200</td>\n    </tr>\n    <tr>\n      <td>42500</td>\n      <td>0.537800</td>\n    </tr>\n    <tr>\n      <td>43000</td>\n      <td>0.551800</td>\n    </tr>\n    <tr>\n      <td>43500</td>\n      <td>0.545500</td>\n    </tr>\n    <tr>\n      <td>44000</td>\n      <td>0.554100</td>\n    </tr>\n    <tr>\n      <td>44500</td>\n      <td>0.542900</td>\n    </tr>\n    <tr>\n      <td>45000</td>\n      <td>0.539500</td>\n    </tr>\n    <tr>\n      <td>45500</td>\n      <td>0.533700</td>\n    </tr>\n    <tr>\n      <td>46000</td>\n      <td>0.527100</td>\n    </tr>\n    <tr>\n      <td>46500</td>\n      <td>0.516100</td>\n    </tr>\n    <tr>\n      <td>47000</td>\n      <td>0.534100</td>\n    </tr>\n    <tr>\n      <td>47500</td>\n      <td>0.535000</td>\n    </tr>\n    <tr>\n      <td>48000</td>\n      <td>0.522300</td>\n    </tr>\n    <tr>\n      <td>48500</td>\n      <td>0.523600</td>\n    </tr>\n    <tr>\n      <td>49000</td>\n      <td>0.513100</td>\n    </tr>\n    <tr>\n      <td>49500</td>\n      <td>0.525800</td>\n    </tr>\n    <tr>\n      <td>50000</td>\n      <td>0.512400</td>\n    </tr>\n    <tr>\n      <td>50500</td>\n      <td>0.518100</td>\n    </tr>\n    <tr>\n      <td>51000</td>\n      <td>0.524400</td>\n    </tr>\n    <tr>\n      <td>51500</td>\n      <td>0.506500</td>\n    </tr>\n    <tr>\n      <td>52000</td>\n      <td>0.516700</td>\n    </tr>\n    <tr>\n      <td>52500</td>\n      <td>0.507100</td>\n    </tr>\n    <tr>\n      <td>53000</td>\n      <td>0.517000</td>\n    </tr>\n    <tr>\n      <td>53500</td>\n      <td>0.518700</td>\n    </tr>\n    <tr>\n      <td>54000</td>\n      <td>0.508900</td>\n    </tr>\n    <tr>\n      <td>54500</td>\n      <td>0.493600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"***** train metrics *****\n  epoch                    =        30.0\n  total_flos               = 124645200GF\n  train_loss               =      0.7863\n  train_runtime            =  5:20:03.13\n  train_samples            =        7326\n  train_samples_per_second =      11.445\n  train_steps_per_second   =       2.862\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"results = {}\nif training_args.do_eval:\n  print((\"*** Evaluate ***\"))\n  metrics = trainer.evaluate(\n      max_length=64, \n      num_beams=4, \n      metric_key_prefix=\"eval\"\n  )\n  max_val_samples = len(encoded_val_ds)\n  metrics[\"eval_samples\"] = min(max_val_samples, len(encoded_val_ds))\n  \n  if trainer.is_world_process_zero():\n    metrics_formatted = trainer.metrics_format(metrics)\n    print(\"***** val metrics *****\")\n    k_width = max(len(str(x)) for x in metrics_formatted.keys())\n    v_width = max(len(str(x)) for x in metrics_formatted.values())\n    for key in sorted(metrics_formatted.keys()):\n      print(f\"  {key: <{k_width}} = {metrics_formatted[key]:>{v_width}}\")\n    save_json(metrics, os.path.join(training_args.output_dir, \"eval_results.json\"))\n    all_metrics.update(metrics)","metadata":{"id":"7bwfdbTLPu6V","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:16:33.673549Z","iopub.execute_input":"2025-04-06T10:16:33.673861Z","iopub.status.idle":"2025-04-06T10:23:58.040432Z","shell.execute_reply.started":"2025-04-06T10:16:33.673835Z","shell.execute_reply":"2025-04-06T10:23:58.039571Z"}},"outputs":[{"name":"stdout","text":"*** Evaluate ***\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ff877d58194785ab6cf2edfe9773a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad47d8e1063d419b8693bfb41041dcea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d30dd7b9b9594f8aaef475d28c6b3cdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09b898a859574448b32ce4ecb69d7a1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3134cccb4814c9cb6cff013991037c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c161ffcb697f47bb870ceab585afe145"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"724b8e906e6d498c865d5bf8b005639e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67664b363d0a45f8878a2162ddcd3a10"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca1e5990d69e4ba59adffa4467dfc565"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d51afee728e493796c67d6eb2982f31"}},"metadata":{}},{"name":"stdout","text":"***** val metrics *****\n  eval_bertscore_f1_0         =       0.85\n  eval_bertscore_f1_1         =       0.88\n  eval_bertscore_precision_0  =       0.84\n  eval_bertscore_precision_1  =       0.86\n  eval_bertscore_recall_0     =       0.87\n  eval_bertscore_recall_1     =        0.9\n  eval_bleu                   =     0.0602\n  eval_bleurt_0               =      -0.41\n  eval_bleurt_1               =       -1.0\n  eval_gen_len                =    57.0859\n  eval_loss                   =     2.1707\n  eval_meteor                 =     0.2707\n  eval_model_preparation_time =     0.0059\n  eval_runtime                = 0:07:24.34\n  eval_sacrebleu              =     6.0199\n  eval_samples                =       1001\n  eval_samples_per_second     =      2.253\n  eval_steps_per_second       =      0.565\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"if training_args.do_predict:\n  print((\"*** Test ***\"))\n  test_results = trainer.predict(\n      encoded_test_ds,\n      metric_key_prefix=\"test\",\n      max_length=64,\n      num_beams=None,\n    )\n  metrics = test_results.metrics\n  max_test_samples = len(encoded_test_ds)\n  metrics[\"test_samples\"] = min(max_test_samples, len(encoded_test_ds))\n    \n  if trainer.is_world_process_zero():\n    metrics_formatted = trainer.metrics_format(metrics)\n    print((\"***** test metrics *****\"))\n    k_width = max(len(str(x)) for x in metrics_formatted.keys())\n    v_width = max(len(str(x)) for x in metrics_formatted.values())\n    for key in sorted(metrics_formatted.keys()):\n      print(f\"  {key: <{k_width}} = {metrics_formatted[key]:>{v_width}}\")\n    save_json(metrics, os.path.join(training_args.output_dir, \"test_results.json\"))\n    all_metrics.update(metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:24:53.650726Z","iopub.execute_input":"2025-04-06T10:24:53.651064Z","iopub.status.idle":"2025-04-06T10:35:35.962820Z","shell.execute_reply.started":"2025-04-06T10:24:53.651037Z","shell.execute_reply":"2025-04-06T10:35:35.961975Z"}},"outputs":[{"name":"stdout","text":"*** Test ***\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","output_type":"stream"},{"name":"stdout","text":"***** test metrics *****\n  test_bertscore_f1_0         =        0.8\n  test_bertscore_f1_1         =       0.83\n  test_bertscore_precision_0  =       0.83\n  test_bertscore_precision_1  =        0.8\n  test_bertscore_recall_0     =       0.78\n  test_bertscore_recall_1     =       0.86\n  test_bleu                   =     0.0659\n  test_bleurt_0               =       -1.1\n  test_bleurt_1               =       -0.8\n  test_gen_len                =    49.7788\n  test_loss                   =      2.119\n  test_meteor                 =     0.2766\n  test_model_preparation_time =     0.0059\n  test_runtime                = 0:10:42.28\n  test_sacrebleu              =     6.5888\n  test_samples                =       2003\n  test_samples_per_second     =      3.119\n  test_steps_per_second       =       0.78\n","output_type":"stream"}],"execution_count":47}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11613456,"sourceType":"datasetVersion","datasetId":7284735}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:31:52.872363Z","iopub.execute_input":"2025-04-29T12:31:52.872742Z","iopub.status.idle":"2025-04-29T12:31:52.882166Z","shell.execute_reply.started":"2025-04-29T12:31:52.872673Z","shell.execute_reply":"2025-04-29T12:31:52.881365Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/feta-dataset/fetaQA-v1_train.jsonl\n/kaggle/input/feta-dataset/fetaQA-v1_dev.jsonl\n/kaggle/input/feta-dataset/fetaQA-v1_test.jsonl\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install torch==2.5.1 transformers==4.44.2 tokenizers==0.19.1 peft==0.12.0 datasets==2.21.0 sentencepiece==0.2.0 accelerate==0.34.2 nltk==3.9.1 evaluate==0.4.3 rouge_score==0.1.2 bert-score==0.3.13 sacrebleu==2.4.3 numpy==1.26.4 fsspec==2024.6.1 spacy==3.7.6 --force-reinstall --no-cache-dir --quiet\n\nimport os\nimport json\nimport numpy as np\nimport torch\nimport nltk\nimport spacy\nfrom datasets import load_dataset\nimport evaluate\nfrom transformers import (\n    AutoConfig,\n    AutoModelForSeq2SeqLM,\n    AutoTokenizer,\n    DataCollatorForSeq2Seq,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    set_seed,\n    GenerationConfig\n)\nfrom peft import LoraConfig, get_peft_model, TaskType\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Set environment variables\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# Download NLTK data\nnltk.download(\"punkt\", quiet=True)\n\n# Load spaCy model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Set random seed for reproducibility\ndef seed_everything(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    set_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\nseed_everything()\n\n# Initialize model and tokenizer\nmodel_name = \"t5-base\"\nconfig = AutoConfig.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name, config=config)\nmodel.resize_token_embeddings(len(tokenizer))\n\n# Enable gradient checkpointing\nmodel.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n\n# Apply LoRA for parameter efficiency\nlora_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    r=16,\n    lora_alpha=64,\n    lora_dropout=0.1,\n    target_modules=[\"q\", \"v\"]\n)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n\n# Load FeTaQA dataset from local JSONL files\ndata_dir = os.getenv(\"DATA_DIR\", \"/kaggle/input/feta-dataset\")  # Replace with your dataset path\ntrain_file = os.path.join(data_dir, 'fetaQA-v1_train.jsonl')\nvalid_file = os.path.join(data_dir, 'fetaQA-v1_dev.jsonl')\ntest_file = os.path.join(data_dir, 'fetaQA-v1_test.jsonl')\n\n# Debug dataset directory\ntry:\n    print(\"Available datasets in data directory:\", os.listdir(os.path.dirname(data_dir)))\n    print(\"Files in feta-dataset:\", os.listdir(data_dir))\n    with open(train_file, 'r') as f:\n        print(\"First 3 lines of fetaQA-v1_train.jsonl:\")\n        for i, line in enumerate(f):\n            if i < 3:\n                try:\n                    parsed = json.loads(line.strip())\n                    print(f\"Line {i+1} (parsed):\", parsed)\n                except json.JSONDecodeError as e:\n                    print(f\"Line {i+1} (raw, failed to parse):\", line.strip(), f\"Error: {e}\")\n            else:\n                break\nexcept FileNotFoundError as fnf:\n    raise FileNotFoundError(\n        f\"Dataset directory {data_dir} or files not found. Please set DATA_DIR environment variable \"\n        f\"to the directory containing fetaQA-v1_train.jsonl, fetaQA-v1_dev.jsonl, and fetaQA-v1_test.jsonl.\"\n    ) from fnf\n\n# Load dataset\ndataset = load_dataset('json', data_files={\n    'train': train_file,\n    'valid': valid_file,\n    'test': test_file\n})\nprint(\"Sample train example:\", dataset['train'][0])\n\n# Question Parsing Module\ndef parse_question(question):\n    \"\"\"\n    Parse the question to extract keywords and classify intent (aggregate, lookup, comparison, ranking).\n    Args:\n        question: The input question string.\n    Returns:\n        Dictionary with keywords (list of str) and intent (str).\n    \"\"\"\n    doc = nlp(question)\n    keywords = [token.text.lower() for token in doc if token.pos_ in [\"NOUN\", \"PROPN\", \"NUM\"]]\n    question_lower = question.lower()\n    \n    if any(word in question_lower for word in [\"total\", \"sum\", \"average\", \"count\"]):\n        intent = \"aggregate\"\n    elif any(word in question_lower for word in [\"highest\", \"lowest\", \"most\", \"least\", \"maximum\", \"minimum\"]):\n        intent = \"comparison\"\n    elif any(word in question_lower for word in [\"rank\", \"order\", \"top\", \"bottom\"]):\n        intent = \"ranking\"\n    else:\n        intent = \"lookup\"\n    \n    return {\"keywords\": keywords, \"intent\": intent}\n\n# Information Retrieval Module\ndef retrieve_relevant_cells(example):\n    \"\"\"\n    Retrieve relevant table cells using highlighted_cell_ids, keyword matching, and TF-IDF fallback.\n    Args:\n        example: Dataset example with table_array, question, highlighted_cell_ids.\n    Returns:\n        List of [row_idx, col_idx] for relevant cells, and intent.\n    \"\"\"\n    table_array = example['table_array']\n    question = example['question']\n    highlighted_cells = example['highlighted_cell_ids']\n    parsed = parse_question(question)\n    keywords = parsed[\"keywords\"]\n    intent = parsed[\"intent\"]\n    \n    header = table_array[0]\n    rows = table_array[1:]\n    \n    # Step 1: Keyword-based column selection\n    relevant_cols = [i for i, col in enumerate(header) if any(kw.lower() in str(col).lower() for kw in keywords)]\n    if not relevant_cols:\n        relevant_cols = [i for i, _ in enumerate(header)]\n    \n    # Step 2: Row selection using highlighted cells and keywords\n    relevant_rows = set()\n    for cell_id in highlighted_cells:\n        if cell_id[0] > 0:\n            relevant_rows.add(cell_id[0] - 1)\n    for i, row in enumerate(rows):\n        if any(any(kw.lower() in str(cell).lower() for kw in keywords) for cell in row):\n            relevant_rows.add(i)\n    \n    # Step 3: TF-IDF fallback if insufficient cells\n    relevant_cells = [[row_idx + 1, col_idx] for row_idx in relevant_rows for col_idx in relevant_cols]\n    if len(relevant_cells) < 2 and rows:\n        all_cells = [f\"{header[j]}: {row[j]}\" for i, row in enumerate(rows) for j in range(len(row))]\n        if all_cells:\n            vectorizer = TfidfVectorizer()\n            cell_vectors = vectorizer.fit_transform(all_cells + [question])\n            similarities = cosine_similarity(cell_vectors[:-1], cell_vectors[-1:])\n            top_indices = np.argsort(similarities.flatten())[::-1][:5]\n            for idx in top_indices:\n                row_idx = idx // len(header)\n                col_idx = idx % len(header)\n                relevant_cells.append([row_idx + 1, col_idx])\n    \n    return relevant_cells, intent\n\n# Reasoning Module\ndef reason_over_cells(table_array, relevant_cells, intent):\n    \"\"\"\n    Reason over retrieved cells based on intent (aggregate, comparison, ranking, lookup).\n    Args:\n        table_array: List of lists representing the table.\n        relevant_cells: List of [row, col] indices.\n        intent: Question intent (aggregate, comparison, ranking, lookup).\n    Returns:\n        String with reasoned output or joined cell contents.\n    \"\"\"\n    if intent == \"aggregate\":\n        values = []\n        for cell in relevant_cells:\n            row, col = cell\n            try:\n                value = float(table_array[row][col])\n                values.append(value)\n            except (ValueError, TypeError):\n                continue\n        if values:\n            if \"average\" in intent.lower():\n                return f\"Average value: {sum(values) / len(values):.2f}\"\n            return f\"Total value: {sum(values):.2f}\"\n    \n    elif intent == \"comparison\":\n        values = []\n        for cell in relevant_cells:\n            row, col = cell\n            try:\n                value = float(table_array[row][col])\n                values.append((value, row, col))\n            except (ValueError, TypeError):\n                continue\n        if values:\n            max_value = max(values, key=lambda x: x[0])\n            min_value = min(values, key=lambda x: x[0])\n            return f\"Highest value: {max_value[0]} (row {max_value[1]}, col {max_value[2]}); Lowest value: {min_value[0]} (row {min_value[1]}, col {min_value[2]})\"\n    \n    elif intent == \"ranking\":\n        values = []\n        for cell in relevant_cells:\n            row, col = cell\n            try:\n                value = float(table_array[row][col])\n                values.append((value, row, col))\n            except (ValueError, TypeError):\n                continue\n        if values:\n            sorted_values = sorted(values, key=lambda x: x[0], reverse=True)\n            return f\"Top value: {sorted_values[0][0]} (row {sorted_values[0][1]}, col {sorted_values[0][2]})\"\n    \n    # Lookup or fallback: Join cell contents with context\n    cell_contents = [str(table_array[row][col]) for row, col in relevant_cells if row < len(table_array) and col < len(table_array[row])]\n    return \" | \".join(cell_contents) if cell_contents else \"No relevant data found\"\n\n# Enhanced Table Linearization\ndef linearize_table_context(example):\n    \"\"\"\n    Linearize table with question, intent, table structure, and reasoning output.\n    Args:\n        example: Dataset example with table_array, question, highlighted_cell_ids.\n    Returns:\n        Linearized string for T5 input.\n    \"\"\"\n    table_array = example['table_array']\n    question = example['question']\n    relevant_cells, intent = retrieve_relevant_cells(example)\n    \n    header = table_array[0]\n    linearized = f\"[QUESTION] {question} [INTENT] {intent} [TABLE] \"\n    linearized += \" | \".join(str(cell) for cell in header) + \" [ROWS] \"\n    \n    for i, row in enumerate(table_array[1:], 1):\n        row_str = []\n        for j, cell in enumerate(row):\n            if [i, j] in relevant_cells:\n                cell = f\"*{cell}*\"\n            row_str.append(str(cell))\n        linearized += \" | \".join(row_str) + \" [ROW] \"\n    \n    reasoning_output = reason_over_cells(table_array, relevant_cells, intent)\n    linearized += f\"[REASONING] {reasoning_output} \"\n    \n    return linearized\n\n# Preprocess dataset\ndef preprocess_examples(examples):\n    \"\"\"\n    Preprocess dataset examples by linearizing inputs and tokenizing.\n    Args:\n        examples: List of dataset examples.\n    Returns:\n        Tokenized model inputs with labels.\n    \"\"\"\n    prefix = 'answer: '\n    inputs = [prefix + linearize_table_context(example) for example in examples]\n    answers = [example['answer'] for example in examples]\n    \n    model_inputs = tokenizer(\n        inputs,\n        max_length=512,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\"\n    )\n    \n    labels = tokenizer(\n        answers,\n        max_length=128,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\"\n    ).input_ids\n    \n    labels = [[-100 if token == tokenizer.pad_token_id else token for token in label] for label in labels]\n    model_inputs[\"labels\"] = labels\n    return model_inputs\n\n# Apply preprocessing\ndef process_batch(batch):\n    \"\"\"\n    Process a batch of examples for dataset mapping.\n    Args:\n        batch: Dataset batch.\n    Returns:\n        Preprocessed batch.\n    \"\"\"\n    keys = batch.keys()\n    batch = [{k: batch[k][i] for k in keys} for i in range(len(batch[list(keys)[0]]))]\n    return preprocess_examples(batch)\n\n# Encode datasets\nencoded_train_ds = dataset['train'].map(process_batch, batched=True, remove_columns=dataset['train'].column_names)\nencoded_val_ds = dataset['valid'].map(process_batch, batched=True, remove_columns=dataset['valid'].column_names)\nencoded_test_ds = dataset['test'].map(process_batch, batched=True, remove_columns=dataset['test'].column_names)\n\n# Post-process text for evaluation\ndef postprocess_text(preds, labels, metric_name):\n    \"\"\"\n    Post-process predictions and labels for metric computation.\n    Args:\n        preds: List of predicted strings.\n        labels: List of reference strings.\n        metric_name: Name of the metric (sacrebleu, rouge, bertscore).\n    Returns:\n        Processed predictions and labels.\n    \"\"\"\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n    if metric_name == \"rouge\":\n        preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n        labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n    elif metric_name == \"sacrebleu\":\n        labels = [[label] for label in labels]\n    return preds, labels\n\n# Compute evaluation metrics\ndef compute_metrics(eval_preds):\n    \"\"\"\n    Compute Sacre-BLEU, ROUGE, and BERTScore metrics.\n    Args:\n        eval_preds: Tuple of (predictions, labels) from the trainer.\n    Returns:\n        Dictionary of metric scores.\n    \"\"\"\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    \n    # Clip token IDs to valid range\n    preds = np.clip(preds, 0, tokenizer.vocab_size - 1)\n    \n    # Decode predictions with error handling\n    decoded_preds = []\n    for pred in preds:\n        try:\n            decoded = tokenizer.decode(pred, skip_special_tokens=True)\n            decoded_preds.append(decoded if decoded else \"<empty>\")\n        except Exception as e:\n            print(f\"Error decoding prediction: {e}\")\n            decoded_preds.append(\"<error>\")\n    \n    # Decode labels\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n    \n    # Save predictions and labels for debugging\n    save_path = os.path.join(training_args.output_dir, \"predictions.json\")\n    with open(save_path, \"w\") as f:\n        json.dump({\"predictions\": decoded_preds, \"labels\": decoded_labels}, f, indent=4)\n    \n    result = {}\n    for metric_name in [\"sacrebleu\", \"rouge\", \"bertscore\"]:\n        metric = evaluate.load(metric_name)\n        decoded_preds_proc, decoded_labels_proc = postprocess_text(decoded_preds, decoded_labels, metric_name)\n        try:\n            if metric_name == \"rouge\":\n                res = metric.compute(predictions=decoded_preds_proc, references=decoded_labels_proc)\n                result.update({f\"rouge{k}\": round(v, 4) for k, v in res.items()})\n            elif metric_name == \"sacrebleu\":\n                res = metric.compute(predictions=decoded_preds_proc, references=decoded_labels_proc)\n                result[\"sacrebleu\"] = round(res[\"score\"], 4)\n            elif metric_name == \"bertscore\":\n                res = metric.compute(predictions=decoded_preds_proc, references=decoded_labels_proc, lang=\"en\", model_type=\"microsoft/deberta-xlarge-v2\")\n                result.update({\n                    \"bertscore_precision\": round(np.mean(res[\"precision\"]), 4),\n                    \"bertscore_recall\": round(np.mean(res[\"recall\"]), 4),\n                    \"bertscore_f1\": round(np.mean(res[\"f1\"]), 4)\n                })\n        except Exception as e:\n            print(f\"Error computing {metric_name}: {e}\")\n            result[metric_name] = 0.0\n    \n    return result\n\n# Training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=os.getenv(\"OUTPUT_DIR\", \"/kaggle/working/\"),\n    overwrite_output_dir=True,\n    do_train=True,\n    do_eval=True,\n    do_predict=True,\n    num_train_epochs=15,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=8,\n    warmup_steps=500,\n    weight_decay=0.01,\n    learning_rate=5e-5,\n    optim=\"adamw_torch\",\n    predict_with_generate=True,\n    generation_max_length=128,\n    generation_num_beams=6,\n    eval_strategy=\"steps\",\n    eval_steps=1000,\n    save_strategy=\"steps\",\n    save_steps=1000,\n    fp16=torch.cuda.is_available(),\n    logging_steps=500,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"sacrebleu\",\n    report_to=\"none\",\n    gradient_checkpointing=True,\n    gradient_checkpointing_kwargs={\"use_reentrant\": False}\n)\n\n# Define generation config for length penalty\ngeneration_config = GenerationConfig(\n    max_length=128,\n    num_beams=6,\n    length_penalty=1.0,\n    no_repeat_ngram_size=2\n)\n\n# Initialize data collator\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer,\n    model=model,\n    label_pad_token_id=-100\n)\n\n# Initialize trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_train_ds,\n    eval_dataset=encoded_val_ds,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate on validation set with generation config\nval_results = trainer.evaluate(encoded_val_ds, generation_config=generation_config)\nprint(\"Validation Results:\", val_results)\n\n# Evaluate on test set with generation config\ntest_results = trainer.predict(encoded_test_ds, generation_config=generation_config)\nprint(\"Test Results:\", test_results.metrics)\n\n# Save the model\ntrainer.save_model(os.path.join(training_args.output_dir, \"tableqa_model\"))\n# Save generation config\ngeneration_config.save_pretrained(os.path.join(training_args.output_dir, \"tableqa_model\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:47:34.387672Z","iopub.execute_input":"2025-04-29T12:47:34.387986Z","iopub.status.idle":"2025-04-29T16:19:39.848676Z","shell.execute_reply.started":"2025-04-29T12:47:34.387964Z","shell.execute_reply":"2025-04-29T16:19:39.847751Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m213.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m223.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m272.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m235.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m233.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m281.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m277.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m274.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.5/102.5 kB\u001b[0m \u001b[31m285.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'spacy' candidate (version 3.7.6 at https://files.pythonhosted.org/packages/89/70/9a54469cf5263d4e4079b329458492a1e150810587b7c82961bee208cfa5/spacy-3.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/spacy/) (requires-python:>=3.7))\nReason for being yanked: Incorrect compatibility for transformer models\u001b[0m\u001b[33m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m268.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m233.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m240.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m318.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m348.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m260.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m336.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m275.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m243.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m224.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m246.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m229.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m294.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m258.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m271.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m213.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m250.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m355.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m263.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m196.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m208.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m216.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m239.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m247.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m211.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m279.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m166.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m263.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.9/218.9 kB\u001b[0m \u001b[31m216.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m288.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m174.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m297.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m171.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m302.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m273.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m270.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m238.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.6/443.6 kB\u001b[0m \u001b[31m315.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m187.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m212.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m334.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m226.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m299.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m174.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m336.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m277.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m155.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m291.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m234.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m130.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m251.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m261.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m287.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m272.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m211.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m163.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m260.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m327.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m263.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m158.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m263.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m208.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m184.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m319.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m156.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m319.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m204.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m316.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m249.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m186.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m235.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m335.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.5/223.5 kB\u001b[0m \u001b[31m311.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m200.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.5/232.5 kB\u001b[0m \u001b[31m302.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m167.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m241.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m216.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m192.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m237.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m339.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m185.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.1/358.1 kB\u001b[0m \u001b[31m268.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m263.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m284.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m250.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m192.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\nsigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\nydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.1 which is incompatible.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.2 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nlangchain-core 0.3.35 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mtrainable params: 1,769,472 || all params: 224,651,520 || trainable%: 0.7877\nAvailable datasets in data directory: ['feta-dataset']\nFiles in feta-dataset: ['fetaQA-v1_train.jsonl', 'fetaQA-v1_dev.jsonl', 'fetaQA-v1_test.jsonl']\nFirst 3 lines of fetaQA-v1_train.jsonl:\nLine 1 (parsed): {'feta_id': 18162, 'table_source_json': 'totto_source/train_json/example-10461.json', 'page_wikipedia_url': 'http://en.wikipedia.org/wiki/1982_Illinois_gubernatorial_election', 'table_page_title': '1982 Illinois gubernatorial election', 'table_section_title': 'Results', 'table_array': [['Party', 'Party', 'Candidate', 'Votes', '%', '±'], ['-', 'Republican', 'James R. Thompson (incumbent)', '1,816,101', '49.44', '-'], ['-', 'Democratic', 'Adlai Stevenson III', '1,811,027', '49.30', '-'], ['-', 'Libertarian', 'Bea Armstrong', '24,417', '0.66', '-'], ['-', 'Taxpayers', 'John E. Roche', '22,001', '0.60', '-'], ['-', 'N/A', 'write-ins', '161', '0.00', 'n-a'], ['Majority', 'Majority', 'Majority', '5,074', '0.14', '-'], ['Turnout', 'Turnout', 'Turnout', '3,673,707', '-', '-'], ['-', 'Republican hold', 'Republican hold', 'Swing', '-', '-']], 'highlighted_cell_ids': [[1, 2], [6, 3]], 'question': 'Who won the 1982 Illinois gubernatorial election, and how many votes was the margin?', 'answer': 'Thompson prevailed in the 1982 Illinois gubernatorial election by a 5,074 vote margin.'}\nLine 2 (parsed): {'feta_id': 11292, 'table_source_json': 'totto_source/train_json/example-3591.json', 'page_wikipedia_url': 'http://en.wikipedia.org/wiki/1986_Indianapolis_500', 'table_page_title': '1986 Indianapolis 500', 'table_section_title': 'Race box score', 'table_array': [['Finish', 'Start', 'No', 'Name', 'Qual', 'Laps', 'Status'], ['1', '4', '3', 'United States Bobby Rahal', '213.550', '200', '170.722 mph'], ['2', '6', '7', 'United States Kevin Cogan', '211.922', '200', '+1.441 seconds'], ['3', '1', '4', 'United States Rick Mears (W)', '216.828', '200', '+1.881 seconds'], ['4', '8', '5', 'Colombia Roberto Guerrero', '211.576', '200', '+10.558 seconds'], ['5', '9', '30', 'United States Al Unser, Jr.', '211.533', '199', 'Flagged'], ['6', '3', '18', 'United States Michael Andretti', '214.522', '199', 'Flagged'], ['7', '11', '20', 'Brazil Emerson Fittipaldi', '210.237', '199', 'Flagged'], ['8', '12', '21', 'United States Johnny Rutherford (W)', '210.220', '198', 'Flagged'], ['9', '2', '1', 'United States Danny Sullivan (W)', '215.382', '197', 'Flagged'], ['10', '13', '12', 'United States Randy Lanier (R)', '209.964', '195', 'Flagged'], ['11', '29', '24', 'United States Gary Bettenhausen', '209.756', '193', 'Flagged'], ['12', '20', '8', 'Australia Geoff Brabham', '207.082', '193', 'Flagged'], ['13', '22', '22', 'Brazil Raul Boesel', '211.202', '192', 'Flagged'], ['14', '33', '23', 'United States Dick Simon', '204.978', '189', 'Flagged'], ['15', '19', '61', 'Netherlands Arie Luyendyk', '207.811', '188', 'Crash T4'], ['16', '14', '15', 'United States Pancho Carter', '209.635', '179', 'Wheel Bearing'], ['17', '10', '66', 'United States Ed Pimm', '210.874', '168', 'Electrical'], ['18', '17', '55', 'Mexico Josele Garza', '208.939', '167', 'Flagged'], ['19', '32', '9', 'Brazil Roberto Moreno (R)', '209.469', '158', 'Stalled'], ['20', '15', '81', 'Canada Jacques Villeneuve (R)', '209.397', '154', 'Main Bearing'], ['21', '25', '59', 'United States Chip Ganassi', '207.590', '151', 'Engine'], ['22', '5', '11', 'United States Al Unser (W)', '212.295', '149', 'Vibration'], ['23', '16', '25', 'United States Danny Ongais', '209.158', '136', 'Ignition'], ['24', '21', '14', 'United States A. J. Foyt (W)', '213.212', '135', 'Spun in pits'], ['25', '27', '6', 'United States Rich Vogler', '209.089', '132', 'Crash T3'], ['26', '31', '84', 'United States George Snider', '209.025', '110', 'Ignition'], ['27', '28', '95', 'United States Johnny Parsons', '207.894', '100', 'CV Joint'], ['28', '18', '16', 'United States Tony Bettenhausen, Jr.', '208.933', '77', 'Valve Spring'], ['29', '26', '31', 'United Kingdom Jim Crawford', '208.911', '70', 'Head Gasket'], ['30', '23', '71', 'United States Scott Brayton', '208.079', '69', 'Engine'], ['31', '24', '42', 'United States Phil Krueger (R)', '207.948', '67', 'Engine'], ['32', '30', '2', 'United States Mario Andretti (W)', '212.300', '19', 'Ignition'], ['33', '7', '33', 'United States Tom Sneva (W)', '211.878', '0', 'Crash T2']], 'highlighted_cell_ids': [[6, 3], [6, 4], [32, 3], [32, 4]], 'question': 'How did Michael and Mario Andretti do?', 'answer': 'Michael Andretti finished with a run of 214.522 mph, faster than Mario.'}\nLine 3 (parsed): {'feta_id': 11734, 'table_source_json': 'totto_source/train_json/example-4033.json', 'page_wikipedia_url': 'http://en.wikipedia.org/wiki/List_of_best-selling_albums_in_Japan', 'table_page_title': 'List of best-selling albums in Japan', 'table_section_title': 'List of best-selling albums by domestic acts', 'table_array': [['No.', 'Album', 'Artist', 'Released', 'Chart', 'Sales'], ['1', 'First Love', 'Hikaru Utada', '10 March 1999', '1', '7,672,000'], ['2', 'B\\'z The Best \"Pleasure\"', \"B'z\", '20 May 1998', '1', '5,136,000'], ['3', 'Review', 'Glay', '1 October 1997', '1', '4,876,000'], ['4', 'Distance', 'Hikaru Utada', '28 March 2001', '1', '4,472,000'], ['5', 'B\\'z The Best \"Treasure\"', \"B'z\", '20 September 1998', '1', '4,439,000'], ['6', 'A Best', 'Ayumi Hamasaki', '28 March 2001', '1', '4,312,000'], ['7', 'Globe', 'Globe', '31 March 1996', '1', '4,136,000'], ['8', 'Deep River', 'Hikaru Utada', '19 June 2002', '1', '3,605,000'], ['9', 'Umi no Yeah!!', 'Southern All Stars', '25 June 1998', '1', '3,592,000'], ['10', 'Delicious Way', 'Mai Kuraki', '28 June 2000', '1', '3,530,000'], ['11', 'Time to Destination', 'Every Little Thing', '15 April 1998', '1', '3,520,000'], ['12', 'Atomic Heart', 'Mr. Children', '1 September 1994', '1', '3,430,000'], ['13', 'Sweet 19 Blues', 'Namie Amuro', '22 July 1996', '1', '3,359,000'], ['14', 'Bolero', 'Mr. Children', '5 March 1997', '1', '3,283,000'], ['15', 'Neue Musik', 'Yumi Matsutoya', '6 November 1998', '1', '3,252,000'], ['16', 'Faces Places', 'Globe', '12 March 1997', '1', '3,239,000'], ['17', 'The Swinging Star', 'Dreams Come True', '14 November 1992', '1', '3,227,000'], ['18', 'Impressions', 'Mariya Takeuchi', '25 July 1994', '1', '3,067,000'], ['19', 'Zard Best the Single Collection ～軌跡～', 'Zard', '28 May 1999', '1', '3,034,000'], ['20', 'All Singles Best', 'Kobukuro', '27 September 2006', '1', '3,018,000']], 'highlighted_cell_ids': [[1, 1], [1, 2], [1, 3], [2, 1], [2, 3], [2, 5]], 'question': 'How many copies did \"Pleasure\" sell in 1998 alone, and how long was it the best selling album in Japan?', 'answer': 'B\\'z The Best \"Pleasure\" sold more than 5 million copies in 1998 alone, making it a temporary best-selling album in Japanese music history, until being surpassed by Utada Hikaru\\'s First Love in 1999.'}\nSample train example: {'feta_id': 18162, 'table_source_json': 'totto_source/train_json/example-10461.json', 'page_wikipedia_url': 'http://en.wikipedia.org/wiki/1982_Illinois_gubernatorial_election', 'table_page_title': '1982 Illinois gubernatorial election', 'table_section_title': 'Results', 'table_array': [['Party', 'Party', 'Candidate', 'Votes', '%', '±'], ['-', 'Republican', 'James R. Thompson (incumbent)', '1,816,101', '49.44', '-'], ['-', 'Democratic', 'Adlai Stevenson III', '1,811,027', '49.30', '-'], ['-', 'Libertarian', 'Bea Armstrong', '24,417', '0.66', '-'], ['-', 'Taxpayers', 'John E. Roche', '22,001', '0.60', '-'], ['-', 'N/A', 'write-ins', '161', '0.00', 'n-a'], ['Majority', 'Majority', 'Majority', '5,074', '0.14', '-'], ['Turnout', 'Turnout', 'Turnout', '3,673,707', '-', '-'], ['-', 'Republican hold', 'Republican hold', 'Swing', '-', '-']], 'highlighted_cell_ids': [[1, 2], [6, 3]], 'question': 'Who won the 1982 Illinois gubernatorial election, and how many votes was the margin?', 'answer': 'Thompson prevailed in the 1982 Illinois gubernatorial election by a 5,074 vote margin.'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d1c9b8b177c4995b12f6e855257ad61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"613482b197824d508d60c715f1957574"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3948' max='6855' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3948/6855 3:28:43 < 2:33:46, 0.32 it/s, Epoch 8.62/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Sacrebleu</th>\n      <th>Rougerouge1</th>\n      <th>Rougerouge2</th>\n      <th>Rougerougel</th>\n      <th>Rougerougelsum</th>\n      <th>Bertscore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>2.000200</td>\n      <td>1.677298</td>\n      <td>14.352500</td>\n      <td>0.427500</td>\n      <td>0.244800</td>\n      <td>0.363900</td>\n      <td>0.364300</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.003700</td>\n      <td>1.677372</td>\n      <td>14.356600</td>\n      <td>0.427700</td>\n      <td>0.245000</td>\n      <td>0.364000</td>\n      <td>0.364300</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.000000</td>\n      <td>nan</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3f4162513174ca5ba30dc8db21ffee4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10b5f44672014e45acf5f852d9ee9404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4505004f83d847f79976b782ce5fff4c"}},"metadata":{}},{"name":"stdout","text":"Error computing bertscore: 'microsoft/deberta-xlarge-v2'\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Error computing bertscore: 'microsoft/deberta-xlarge-v2'\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Error computing bertscore: 'microsoft/deberta-xlarge-v2'\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1569910546.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;31m# Evaluate on validation set with generation config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3347\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3348\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3349\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2190\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}